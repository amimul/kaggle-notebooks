{
 "metadata": {
  "kernelspec": {
   "name": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0,
 "cells": [
  {
   "cell_type": "code",
   "source": "import numpy as np\n\nimport scipy as sp\nimport scipy.ndimage as ndi\nfrom scipy.signal import argrelextrema\n\nimport pandas as pd\n\nfrom skimage import measure\nfrom sklearn import metrics\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\n%matplotlib inline\nfrom pylab import rcParams\nrcParams['figure.figsize'] = (6, 6)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ----------------------------------------------------- I/O ---\n\ndef read_img(img_no):\n    \"\"\"reads image from disk\"\"\"\n    return mpimg.imread('../input/images/' + str(img_no) + '.jpg')\n\n\ndef get_imgs(num):\n    \"\"\"convenience function, yields random sample from leaves\"\"\"\n    if type(num) == int:\n        imgs = range(1, 1584)\n        num = np.random.choice(imgs, size=num, replace=False)\n        \n    for img_no in num:\n        yield img_no, preprocess(read_img(img_no))",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\n# ----------------------------------------------------- preprocessing ---\n\ndef threshold(img, threshold=250):\n    \"\"\"splits img to 0 and 255 values at threshold\"\"\"\n    return ((img > threshold) * 255).astype(img.dtype)\n\n\ndef portrait(img):\n    \"\"\"makes all leaves stand straight\"\"\"\n    y, x = np.shape(img)\n    return img.transpose() if x > y else img\n    \n\ndef resample(img, size):\n    \"\"\"resamples img to size without distorsion\"\"\"\n    ratio = size / max(np.shape(img))\n    return sp.misc.imresize(img, ratio, mode='L', interp='nearest')\n\n    \ndef fill(img, size=500, tolerance=0.95):\n    \"\"\"extends the image if it is signifficantly smaller than size\"\"\"\n    y, x = np.shape(img)\n\n    if x <= size * tolerance:\n        pad = np.zeros((y, int((size - x) / 2)), dtype=int)\n        img = np.concatenate((pad, img, pad), axis=1)\n\n    if y <= size * tolerance:\n        pad = np.zeros((int((size - y) / 2), x), dtype=int)\n        img = np.concatenate((pad, img, pad), axis=0) \n    \n    return img",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ----------------------------------------------------- postprocessing ---\n\ndef standardize(arr1d):\n    \"\"\"move mean to zero, 1st SD to -1/+1\"\"\"\n    return (arr1d - arr1d.mean()) / arr1d.std()\n\n\ndef coords_to_cols(coords):\n    \"\"\"from x,y pairs to feature columns\"\"\"\n    return coords[::,1], coords[::,0]\n\n\ndef get_contour(img):\n    \"\"\"returns the coords of the longest contour\"\"\"\n    return max(measure.find_contours(img, .8), key=len)\n\n\ndef downsample_contour(coords, bins=512):\n    \"\"\"splits the array to ~equal bins, and returns one point per bin\"\"\"\n    edges = np.linspace(0, coords.shape[0], \n                       num=bins).astype(int)\n    for b in range(bins-1):\n        yield [coords[edges[b]:edges[b+1],0].mean(), \n               coords[edges[b]:edges[b+1],1].mean()]\n\n\ndef get_center(img):\n    \"\"\"so that I do not have to remember the function ;)\"\"\"\n    return ndi.measurements.center_of_mass(img)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ----------------------------------------------------- feature engineering ---\n\ndef extract_shape(img):\n    \"\"\"\n    Expects prepared image, returns leaf shape in img format.\n    The strength of smoothing had to be dynamically set\n    in order to get consistent results for different sizes.\n    \"\"\"\n    size = int(np.count_nonzero(img)/1000)\n    brush = int(5 * size/size**.75)\n    return ndi.gaussian_filter(img, sigma=brush, mode='nearest') > 200\n\n\ndef near0_ix(timeseries_1d, radius=5):\n    \"\"\"finds near-zero values in time-series\"\"\"\n    return np.where(timeseries_1d < radius)[0]\n\n\ndef dist_line_line(src_arr, tgt_arr):\n    \"\"\"\n    returns 2 tgt_arr length arrays, \n    1st is distances, 2nd is src_arr indices\n    \"\"\"\n    return np.array(sp.spatial.cKDTree(src_arr).query(tgt_arr))\n\n\ndef dist_line_point(src_arr, point):\n    \"\"\"returns 1d array with distances from point\"\"\"\n    point1d = [[point[0], point[1]]] * len(src_arr)\n    return metrics.pairwise.paired_distances(src_arr, point1d)\n\n\ndef index_diff(kdt_output_1):\n    \"\"\"\n    Shows pairwise distance between all n and n+1 elements.\n    Useful to see, how the dist_line_line maps the two lines.\n    \"\"\"\n    return np.diff(kdt_output_1)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ----------------------------------------------------- wrapping functions ---\n\n# wrapper function for all preprocessing tasks    \ndef preprocess(img, do_portrait=True, do_resample=500, \n               do_fill=True, do_threshold=250):\n    \"\"\" prepares image for processing\"\"\"\n    if do_portrait:\n        img = portrait(img)\n    if do_resample:\n        img = resample(img, size=do_resample)\n    if do_fill:\n        img = fill(img, size=do_resample)\n    if do_threshold:\n        img = threshold(img, threshold=do_threshold)\n        \n    return img\n\n\n# wrapper function for feature extraction tasks\ndef get_std_contours(img):\n    \"\"\"from image to standard-length countour pairs\"\"\"\n    \n    # shape in boolean n:m format\n    blur = extract_shape(img) \n    \n    # contours in [[x,y], ...] format\n    blade = np.array(list(downsample_contour(get_contour(img))))\n    shape = np.array(list(downsample_contour(get_contour(blur))))\n    \n    # flagging blade points that fall inside the shape contour\n    # notice that we are loosing subpixel information here\n    blade_y, blade_x = coords_to_cols(blade)\n    blade_inv_ix = blur[blade_x.astype(int), blade_y.astype(int)]\n    \n    # img and shape centers\n    shape_cy, shape_cx = get_center(blur)\n    blade_cy, blade_cx = get_center(img)\n    \n    # img distance, shape distance (for time series plotting)\n    blade_dist = dist_line_line(shape, blade)\n    shape_dist = dist_line_point(shape, [shape_cx, shape_cy])\n\n    # fixing false + signs in the blade time series\n    blade_dist[0, blade_inv_ix] = blade_dist[0, blade_inv_ix] * -1\n    \n    return {'shape_img': blur,\n            'shape_contour': shape, \n            'shape_center': (shape_cx, shape_cy),\n            'shape_series': [shape_dist, range(len(shape_dist))],\n            'blade_img': img,\n            'blade_contour': blade,\n            'blade_center': (blade_cx, blade_cy),\n            'blade_series': blade_dist,\n            'inversion_ix': blade_inv_ix}\n    ",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "title, img = list(get_imgs(1))[0]\nfeatures = get_std_contours(img)\n\nplt.subplot(121)\nplt.plot(*coords_to_cols(features['shape_contour']))\nplt.plot(*coords_to_cols(features['blade_contour']))\n#plt.axis('equal')\n\nplt.subplot(122)\nplt.plot(*features['shape_series'])\nplt.plot(*features['blade_series'])",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# determining eigenvalues and eigenvectors for the leaves\n# and drawing 2SD ellipse around its center as a 3rd descriptor\n\nfrom matplotlib.patches import Ellipse\n\nstandard_deviations = 1\nx_imgsize, y_imgsize = features['shape_img'].shape\n\n# generating rnd coords\nx_rnd = np.random.randint(x_imgsize, size=2048)\ny_rnd = np.random.randint(y_imgsize, size=2048)\nrnd_coords = np.array([y_rnd, x_rnd])\n\n# checking rnd coords against shape, keep only the ones inside\nshape_mask = features['shape_img'][x_rnd, y_rnd]\nsampled_coords = rnd_coords[0, shape_mask], rnd_coords[1, shape_mask]\n\n# this is actually a PCA, visualized as an ellipse\ncovariance_matrix = np.cov(sampled_coords)\neigenvalues, eigenvectors = pd.np.linalg.eigh(covariance_matrix)\norder = eigenvalues.argsort()[::-1]\neigenvectors = eigenvectors[:,order]\ntheta = pd.np.rad2deg(pd.np.arctan2(*eigenvectors[0]) % (2 * pd.np.pi))\nwidth, height = 2 * standard_deviations * pd.np.sqrt(eigenvalues)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# visualization\nellipse = Ellipse(xy=features['shape_center'],\n                  width=width, height=height, angle=theta, \n                  fc='none', color='k')\n\nax = plt.subplot(111)\n\nax.add_artist(ellipse)\nax.plot(*coords_to_cols(features['shape_contour']))\nax.plot(*coords_to_cols(features['blade_contour']))\nax.axis('equal')\nplt.show()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  }
 ]
}
